{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAgger on Part of Speech tagging\n",
    "\n",
    "This notebook shows how to run the imitation learning algorithm DAgger (Dataset Aggregation, [Ross et al. (2011)](https://arxiv.org/pdf/1011.0686.pdf)) on a toy part of speech tagging dataset, showcasing its benefits. It follows the terminology of the EACL 2017 tutorial on imitation learning for structured prediction ([Vlachos et al. 2017](http://sheffieldnlp.github.io/ImitationLearningTutorialEACL2017/)) and the code from this [github repository](http://github.com/andreasvlachos/structured_imitation_demo). The latter uses [scikit-learn](http://scikit-learn.org/stable/) classifiers in Python3 to faciliate adoptions by academic researchers and software developers. The notebook follows closely the code in this [file](http://github.com/andreasvlachos/structured_imitation_demo/blob/master/src/POSdemo.py), if you would rather go straight there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows we show how to do this step-by-step. First import the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the (typically structured) input and the structured output, combined in an instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class POSInput(imitation.StructuredInput):\n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = tokens  \n",
    "\n",
    "class POSOutput(imitation.StructuredOutput):\n",
    "    def __init__(self, tags=None):\n",
    "        self.tags = []\n",
    "        if tags!=None:\n",
    "            self.tags = tags\n",
    "\n",
    "class POSInstance(imitation.StructuredInstance):\n",
    "    def __init__(self, tokens, tags=None):\n",
    "        super().__init__()\n",
    "        self.input = POSInput(tokens)\n",
    "        self.output = POSOutput(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the work is defining the transition system. The package has a class ```TransitionSystem``` that helps define it. See the comments in the code for some hints about its construction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class POSTransitionSystem(imitation.TransitionSystem):\n",
    "\n",
    "    class WordAction(imitation.TransitionSystem.Action):\n",
    "        def __init__(self):\n",
    "            # The superclass constructor initializes the label and the features that each action has\n",
    "            super().__init__()\n",
    "\n",
    "    # the agenda for word prediction is one action per token, left-to-right\n",
    "    def __init__(self, structured_instance=None):\n",
    "        super().__init__(structured_instance)\n",
    "        if structured_instance == None:\n",
    "            return\n",
    "        for tokenNo, token in enumerate(structured_instance.input.tokens):\n",
    "            newAction = self.WordAction()\n",
    "            newAction.tokenNo = tokenNo\n",
    "            self.agenda.append(newAction)\n",
    "\n",
    "    # the expert policy is trivial in the case of PoS tagging: just return the correct label from gold\n",
    "    def expert_policy(self, structured_instance, action):\n",
    "        # just return the next action\n",
    "        return structured_instance.output.tags[action.tokenNo]\n",
    "\n",
    "    # Here we could be doing more book-keeping to help extract more complex features\n",
    "    def updateWithAction(self, action, structuredInstance):\n",
    "        # add it as an action though\n",
    "        self.actionsTaken.append(action)\n",
    "\n",
    "    # The feature engineering goes here\n",
    "    def extractFeatures(self, structured_instance, action):\n",
    "        # e.g the word itself that we are tagging\n",
    "        features = {\"currentWord=\" + structured_instance.input.tokens[action.tokenNo]: 1}\n",
    "\n",
    "        # features based on the previous predictionsof this stage are to be accessed via the self.actionsTaken\n",
    "        # e.g. the previous action\n",
    "        if len(self.actionsTaken) > 0:\n",
    "            features[\"prevPrediction=\" + self.actionsTaken[-1].label] = 1\n",
    "        else:\n",
    "            features[\"prevPrediction=NULL\"] = 1\n",
    "\n",
    "        return features\n",
    "\n",
    "    # Convert the action sequence in the state to the actual prediction, i.e. a sequence of tags\n",
    "    def to_output(self):\n",
    "        tags = []\n",
    "        for action in self.actionsTaken:\n",
    "            tags.append(action.label)\n",
    "        return POSOutput(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is it! We can now write the following which specifies that our tagger will be learned by the ```ImitationLearner``` with the ```POSTransitionSystem```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class POSTagger(imitation.ImitationLearner):\n",
    "    # specify the transition system\n",
    "    transitionSystem = POSTransitionSystem\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a toy dataset and an instance of the tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainingInstances = []\n",
    "\n",
    "# two instances\n",
    "trainingInstances.extend([POSInstance([\"I\", \"can\", \"fly\"], [\"Pronoun\", \"Modal\", \"Verb\"])])\n",
    "trainingInstances.extend([POSInstance([\"I\", \"can\", \"meat\"], [\"Pronoun\", \"Verb\", \"Noun\"])])\n",
    "\n",
    "# repeated multiple times\n",
    "trainingInstances.extend(30*[POSInstance([\"I\", \"can\", \"fly\"], [\"Pronoun\", \"Modal\", \"Verb\"])])\n",
    "trainingInstances.extend(10*[POSInstance([\"I\", \"can\", \"meat\"], [\"Pronoun\", \"Verb\", \"Noun\"])])\n",
    "\n",
    "tagger = POSTagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the features (current word, previous tag), the classifier receives an ambiguous training signal. Thus it will learn to predict only one of the two cases of \"can\" correctly, the one with more appearances in the training data. Of course more complex features could address this, but generally speaking we rarely (want to) have features that are too complex as they tend to be sparse and not generalize. Let's see what happens here when training with 1 iteration of DAgger, which is the equivalent of standard supervised training, also referred to as exact imitation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    params.iterations = 1\n",
    "\n",
    "    tagger.train(trainingInstances, params)\n",
    "\n",
    "    print(tagger.labelEncoder.classes_)\n",
    "    print(tagger.vectorizer.inverse_transform(tagger.model.coef_))\n",
    "\n",
    "    print(tagger.predict(trainingInstances[0]).to_output())\n",
    "    print(tagger.predict(trainingInstances[1]).to_output())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgments\n",
    "\n",
    "I have been working on imitation learning for structured prediction for many years with many great collaborators: Special thanks to Gerasimos Lampouras and Sebastian Riedel who worked with me on preparing the aforementioned EACL 2017 tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
