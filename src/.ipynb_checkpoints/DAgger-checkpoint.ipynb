{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAgger on Part of Speech tagging\n",
    "\n",
    "This notebook shows how to run the imitation learning algorithm DAgger (Dataset Aggregation, [Ross et al. (2011)](https://arxiv.org/pdf/1011.0686.pdf)) on a toy part of speech tagging dataset, showcasing its benefits. It follows the terminology of the EACL 2017 tutorial on imitation learning for structured prediction ([Vlachos et al. 2017](http://sheffieldnlp.github.io/ImitationLearningTutorialEACL2017/)) and the code from this [github repository](http://github.com/andreasvlachos/structured_imitation_demo). The latter uses [scikit-learn](http://scikit-learn.org/stable/) classifiers in Python3 to faciliate adoptions by academic researchers and software developers. The notebook follows closely the code in this [file](http://github.com/andreasvlachos/structured_imitation_demo/blob/master/src/POSdemo.py), if you would rather go straight there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows we show how to do this step-by-step. First import the library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the (typically structured) input and the structured output, combined in an instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class POSInput(imitation.StructuredInput):\n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = tokens  \n",
    "\n",
    "class POSOutput(imitation.StructuredOutput):\n",
    "    def __init__(self, tags=None):\n",
    "        self.tags = []\n",
    "        if tags!=None:\n",
    "            self.tags = tags\n",
    "\n",
    "class POSInstance(imitation.StructuredInstance):\n",
    "    def __init__(self, tokens, tags=None):\n",
    "        super().__init__()\n",
    "        self.input = POSInput(tokens)\n",
    "        self.output = POSOutput(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the work is defining the transition system. The package has a class ```TransitionSystem``` that helps define it. See the comments in the code for some hints about its construction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSTransitionSystem(imitation.TransitionSystem):\n",
    "\n",
    "    class WordAction(imitation.TransitionSystem.Action):\n",
    "        def __init__(self):\n",
    "            # The superclass constructor initializes the label and the features that each action has\n",
    "            super().__init__()\n",
    "\n",
    "    # the agenda for word prediction is one action per token, left-to-right\n",
    "    def __init__(self, structured_instance=None):\n",
    "        super().__init__(structured_instance)\n",
    "        if structured_instance == None:\n",
    "            return\n",
    "        for tokenNo, token in enumerate(structured_instance.input.tokens):\n",
    "            newAction = self.WordAction()\n",
    "            newAction.tokenNo = tokenNo\n",
    "            self.agenda.append(newAction)\n",
    "\n",
    "    # the expert policy is trivial in the case of PoS tagging: just return the correct label from gold\n",
    "    def expert_policy(self, structured_instance, action):\n",
    "        # just return the next action\n",
    "        return structured_instance.output.tags[action.tokenNo]\n",
    "\n",
    "    # In principle we could be doing more book-keeping \n",
    "    def updateWithAction(self, action, structuredInstance):\n",
    "        # add it as an action though\n",
    "        self.actionsTaken.append(action)\n",
    "\n",
    "    # all the feature engineering goes here\n",
    "    def extractFeatures(self, structured_instance, action):\n",
    "        # e.g the word itself that we are tagging\n",
    "        features = {\"currentWord=\" + structured_instance.input.tokens[action.tokenNo]: 1}\n",
    "\n",
    "        # features based on the previous predictionsof this stage are to be accessed via the self.actionsTaken\n",
    "        # e.g. the previous action\n",
    "        if len(self.actionsTaken) > 0:\n",
    "            features[\"prevPrediction=\" + self.actionsTaken[-1].label] = 1\n",
    "        else:\n",
    "            features[\"prevPrediction=NULL\"] = 1\n",
    "\n",
    "        # features based on earlier stages via the state variable.\n",
    "\n",
    "        return features\n",
    "\n",
    "    def to_output(self):\n",
    "        \"\"\"\n",
    "        Convert the action sequence in the state to the\n",
    "        actual prediction, i.e. a sequence of tags\n",
    "        \"\"\"\n",
    "        tags = []\n",
    "        for action in self.actionsTaken:\n",
    "            tags.append(action.label)\n",
    "        return POSOutput(tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgments\n",
    "\n",
    "Gerasimos, Sebastian"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
